# Curso CoderHouse Data Science

üëã Bienvenido/da

# Desafios

- Los desafios completados del Curso son los siguientes:

## Desafio CrossValidation y mejora de modelos de ML

- Requerimientos:

    - Entrenar uno de los modelos elegidos con las mismas variables pero aplicando alguno de los m√©todos aprendidos de validaci√≥n cruzada

        - Se utilizaron metodos K-Fold Cross Validation y Stratified K-Fold, en ambos casos K = 10, cuyos resultados fueron:

            - K-Fold Cross Validation - Average RMSE: 0.41374959814893586
            - Stratified K-Fold - Average RMSE: 0.4015367414501386

    - Describir si hay cambios en el performance del modelo y explicar con razones el porqu√©

        - Metodo K-Fold Cross Validation: 
        
            Las conclusiones para el m√©todo K-Fold Cross Validation son las siguientes:

                - El RMSE obtenido es mayor que el obtenido con el modelo original, lo que sugiere que el modelo es menos preciso cuando se utiliza K-Fold Cross Validation.

                - Este resultado puede deberse a que K-Fold Cross Validation utiliza una validaci√≥n cruzada estratificada, lo que significa que cada partici√≥n tiene una distribuci√≥n de clases similar a la distribuci√≥n de clases en el conjunto de datos completo. En este caso, el conjunto de datos tiene dos clases: jugadores que marcaron goles y jugadores que no marcaron goles. Al utilizar K-Fold Cross Validation, nos aseguramos de que cada partici√≥n tenga un n√∫mero similar de jugadores que marcaron goles y jugadores que no marcaron goles. Esto puede ayudar a mejorar la precisi√≥n del modelo de aprendizaje autom√°tico, pero tambi√©n puede introducir sesgos en los resultados.

            Para mejorar la precisi√≥n del modelo con K-Fold Cross Validation, podemos considerar las siguientes soluciones:

                - Utilizar un n√∫mero mayor de particiones. Esto ayudar√° a reducir el sesgo introducido por la validaci√≥n cruzada estratificada.

                - Utilizar un m√©todo de validaci√≥n no estratificado. Esto puede ayudar a mejorar la precisi√≥n del modelo en general, pero tambi√©n puede introducir sesgos en los resultados.

                - Utilizar un modelo de aprendizaje autom√°tico diferente. Algunos modelos, como los modelos de regresi√≥n lineal, pueden ser m√°s precisos que los modelos de regresi√≥n de bosque aleatorio cuando se utilizan m√©todos de validaci√≥n cruzada.

        - Metodo Stratified K-Fold:

            Las conclusiones para el m√©todo Stratified K-Fold son las siguientes:

                - El RMSE obtenido es mayor que el obtenido con el modelo Random Forest Regressor, lo que sugiere que el modelo es menos preciso.

                - Este resultado es esperado, ya que Stratified K-Fold toma en cuenta la distribuci√≥n de las clases en los datos. En este caso, el conjunto de datos tiene dos clases: jugadores que marcaron goles y jugadores que no marcaron goles. 

            Al utilizar Stratified K-Fold, nos aseguramos de que cada partici√≥n tenga un n√∫mero similar de jugadores que marcaron goles y jugadores que no marcaron goles. Esto puede ayudar a mejorar la precisi√≥n del modelo de aprendizaje autom√°tico, pero tambi√©n puede reducir la precisi√≥n en los casos en que el modelo est√° bien entrenado para predecir una clase en particular.

            
            Para mejorar la precisi√≥n del modelo utilizando Stratified K-Fold:

                - podemos aumentar el n√∫mero de particiones. Esto ayudar√° a que el modelo tenga m√°s datos de entrenamiento para cada clase.

                - Otra opci√≥n es utilizar un m√©todo de validaci√≥n cruzada que no tome en cuenta la distribuci√≥n de las clases. Por ejemplo, podemos utilizar K-Fold con un n√∫mero de particiones impar. Esto ayudar√° a que el modelo tenga una partici√≥n completa para cada clase.
            

## Desafio Ingenier√≠a de atributos y selecci√≥n de variables

- Requerimientos:

    - Crear variables sint√©ticas adicionales que permitan mejorar el desempe√±o del modelo de ML en la entrega anterior.

        - Las variables sinteticas adicionales son:

            - Sh_per_90: N√∫mero de tiros por 90 minutos jugados
            - SoT_per_90: N√∫mero de oportunidades de gol por 90 minutos jugados
            - G_per_SoT: N√∫mero de goles por oportunidad de gol

    - Probar distintos modelos y elegir el mejor teniendo en cuenta el Bias-Variance tradeoff

        - Se analizaron 4 modelos:

            - Regresion Lineal
            - Random Forest 
            - Regresion Logistica 
            - Soporte Vectorial

        - Los resultados obtenidos fueron:

            - Regresion Lineal RMSE: 1.2833453636096384
            - Bosque Aleatorio RMSE: 0.3534165543230328
            - Regresion Logistica accuracy: 0.6322463768115942
            - Soporte Vectorial accuracy: 0.49818840579710144

            En general, los resultados obtenidos indican que los modelos de aprendizaje autom√°tico supervisado, como el bosque aleatorio y la regresi√≥n log√≠stica, son m√°s precisos para predecir los goles de un jugador de f√∫tbol que los modelos de aprendizaje autom√°tico no supervisado, como el soporte vectorial.
        
    - Realizar PCA sobre las variables usadas y explorar las cargas de los 2 primeros componentes, identificar las variables m√°s relevantes.

        -   Resultados de PCA:

            - Componente 1: Est√° fuertemente correlacionado con las variables Sh, SoT, SoT_per_90 y Sh_per_90. Esto sugiere que este componente representa la cantidad de disparos que realiza un jugador de f√∫tbol y la precisi√≥n de esos disparos.

            - Componente 2: Est√° fuertemente correlacionado con las variables Gls, FK y Dist. Esto sugiere que este componente representa la productividad goleadora de un jugador de f√∫tbol, tanto en tiros directos como en tiros lejanos.

- Archivo Implementaci√≥n Desafio:

https://github.com/IngLuissolis/CoderHouseDataScience/tree/main/Desafios/Desafio_FeatureSelection_Luis_Solis.ipynb

## Desafio Evaluando modelos de Machine Learning

- Requerimientos:

    - Realizar una segunda ronda de Feature Engineering con el fin de ampliar el n√∫mero de variables incluidas en el modelo MVP de la entrega anterior.

        -   Al nuevo data set se agregan las variables:

            - Sh (Shots): N√∫mero total de tiros realizados por un jugador.

            - SoT (Shots on target): N√∫mero total de tiros que han ido a puerta.

            - SoT% (Shots on target percentage): Porcentaje de tiros que han ido a puerta.

            - Sh/90 (Shots per 90 minutes): N√∫mero medio de tiros realizados por un jugador por partido.

            - SoT/90 (Shots on target per 90 minutes): N√∫mero medio de tiros que han ido a puerta por partido.

            - G/Sh (Goals per shot): N√∫mero medio de goles marcados por un jugador por cada tiro realizado.

            - G/SoT (Goals per shot on target): N√∫mero medio de goles marcados por un jugador por cada tiro que ha ido a puerta.

            - Dist (Distance): Distancia media de los tiros realizados por un jugador.

            - FK (Free kicks): N√∫mero total de tiros libres realizados por un jugador.

            - npxG/Sh (Non-penalty expected goals per shot): N√∫mero medio de goles esperados por un jugador por cada tiro realizado, excluyendo los goles marcados desde el punto de penalti.

    - Realizar una segunda ronda de entrenamiento con m√°s variables.

    Los resultados obtenidos para el nuevo dataset (modelo 2) son:

        - feature selection - Selecci√≥n de caracteristicas univariadas - Regresi√≥n Lineal - Variable Gls (Goles):
        
            - Mean Squared Error (MSE): 3.3632029571995354e-06
            - R-squared (R2): 0.999999720098907

        - feature selection - Selecci√≥n de caracteristicas univariadas - Regresi√≥n Lineal - Variable Ast (Asistencias):

            - Mean Squared Error (MSE): 5.851615851581933e-29
            - R-squared (R2): 1.0

    - Comparar la performance de ambos modelos en el conjunto de testeo.

        - Modelo 1: Resultados de Desafio Anterior
        - Modelo 2: Resultados de Actual Desafio, con incorporacion de nuevas variables

        - Resultados de comparaci√≥n:

            - Variable Goles: 
                    - El modelo 2 es mejor que el modelo 1 en t√©rminos de MSE.
                    - La mejora es de un 20%.
                    - El modelo 2 es m√°s complejo y requiere m√°s datos para entrenar.
            
            - Variable Asistencias:
                    - En un conjunto de testeo, los modelos de regresi√≥n lineal para predecir asistencias de jugadores tienen un MSE muy bajo y un R2 muy alto. 
                    - El modelo 1 es ligeramente m√°s preciso que el modelo 2.

- Archivo Implementaci√≥n Desafio:

https://github.com/IngLuissolis/CoderHouseDataScience/tree/main/Desafios/Desafio_EvaluacionML_Luis+Solis.ipynb

## Desafio Entrenando un algoritmo de Machine Learning

- Requerimientos:

    - Utilizar una fuente de datos para resolver problemas de clasificaci√≥n o regresi√≥n.

    - Realizar los procesos de Encoding, Feature Engineering y entrenamiento de un modelo de Machine Learning (Clasificaci√≥n o Regresi√≥n).

    - Archivo Implementaci√≥n Desafio:

https://github.com/IngLuissolis/CoderHouseDataScience/tree/main/Desafios/Desafio_AlgoritmoML_MVP_Luis_Solis.ipynb


## Desafio Segunda Pre entrega:

- Requerimientos:

    - Generar insights que permitan dar respuesta a las preguntas por responder.

    - Archivo Implementaci√≥n Desafio:

https://github.com/IngLuissolis/CoderHouseDataScience/tree/main/Desafios/SegundaPreEntregaProyectoFinal+Solis.ipynb

## Desafio Obtenci√≥n de insights:

- Requerimientos:

    - Generar insights que permitan dar respuesta a las preguntas por responder.

    - Archivo Implementaci√≥n Desafio:

https://github.com/IngLuissolis/CoderHouseDataScience/tree/main/Desafios/Obtencion_de_insights+Solis.ipynb


https://github.com/IngLuissolis/CoderHouseDataScience/tree/main/Desafios/An√°lisis_Datos_F√∫tbol.pptx

## Desafio Data Storytelling:

- Requerimientos:

    - Iniciar el proceso de Data Storytelling respondiendo las preguntas que se quieran responder.

    - Archivo Implementaci√≥n Desafio:

https://github.com/IngLuissolis/CoderHouseDataScience/tree/main/Desafios/Data_Storytelling+Solis.ipynb

## Desafio Data Wrangling:

- Requerimientos:

    - Iniciar el proceso de limpieza y exploraci√≥n de datos seg√∫n el dataset elegido para el proyecto final.

    - Archivo Implementaci√≥n Desafio:

https://github.com/IngLuissolis/CoderHouseDataScience/tree/main/Desafios/Data_Wrangling+Solis.ipynb

- Consideraciones:

    - Se encontro un valor NaN - fila 1875, columna "Nation", para player David Ozoh. Se cambia por valor "ENG", correspondiente a nacional England.

    - Se encuentra 105 valores con nombres de jugadores que contienen caracter "?". Ejemplo: 
        - Fila: 95, columna: Player, valor: Komnen Andri? 
        - Nombre Correcto:  'Komnen Andriƒá'

        - Se cambian los valores de los 105 nombres.

## Descarga de datos desde APIs publicas

- Requerimientos:

    - Buscar informaci√≥n en APIs p√∫blicas (i.e Twitter, NewsAPI, Spotify, Google Apis, etc).
    - Extraer datos e importarlos a un dataframe realizando una exploraci√≥n simple (i.e filas, columnas, tipos de datos).

- Archivo Implementaci√≥n Desafio:

https://github.com/IngLuissolis/CoderHouseDataScience/tree/main/Desafios/Desafio_APIS_Luis+Solis.ipynb

## Primera Entrega Proyecto Final

- Requerimientos:

    - Estructurar un problema en funci√≥n de m√∫ltiples, pero simples preguntas/hip√≥tesis a responder
    - Analizar datos tabulares (e.g excel, csv, etc)  usando Python
    - Utilizar modelos de Machine Learning con Python

- Archivo Implementaci√≥n Desafio:

https://github.com/IngLuissolis/CoderHouseDataScience/tree/main/Desafios/ProyectoFinal+LSolis.ipynb

- Consideraciones:

    - Lo analizado en Archivo ProyectoFinal+LSolis.ipynb es un compilado de los desafios anteriores.
    - Se selecciona modelo Random Forest ya que tiene mejor performance que modelo Elastic Net, de acuerdo a lo analizado en el desafio anterior.

## Desafio Complementario Evaluando Modelos ML

- Requerimientos:

    - Generar una evaluaci√≥n de modelos apropiados para el problema de inter√©s.
    - Identificar por medio de las m√©tricas generadas si se puede tener una situaci√≥n de overfitting (sobreajuste) o underfitting (subajuste), discutiendo posibles formas de mejora

- Archivo Implementaci√≥n Desafio:

https://github.com/IngLuissolis/CoderHouseDataScience/tree/main/Desafios/ProyectoDS_ParteIII_Solis_III.ipynb

- Consideraciones:

    - Se implementaron modelos Random Forest y Elastic Net. Resultados:

        - Random Forest: 
            - Error cuadr√°tico medio (MSE) - Conjunto de entrenamiento: 3.420932607883566
            - Error cuadr√°tico medio (MSE) - Conjunto de prueba: 2.903501202996976
            - Coeficiente de determinaci√≥n (R^2) - Conjunto de entrenamiento: 0.16256611515822927
            - Coeficiente de determinaci√≥n (R^2) - Conjunto de prueba: 0.2603353991224575
            - Error absoluto medio (MAE) - Conjunto de entrenamiento: 0.31082945339684603
            - Error absoluto medio (MAE) - Conjunto de prueba: 0.399162829832605

        - Elastic Net:
            - Error cuadr√°tico medio (MSE) - Conjunto de entrenamiento: 3.420932607883566
            - Error cuadr√°tico medio (MSE) - Conjunto de prueba: 2.903501202996976
            - Coeficiente de determinaci√≥n (R^2) - Conjunto de entrenamiento: 0.16256611515822927
            - Coeficiente de determinaci√≥n (R^2) - Conjunto de prueba: 0.2603353991224575
            - Error absoluto medio (MAE) - Conjunto de entrenamiento: 0.31082945339684603
            - Error absoluto medio (MAE) - Conjunto de prueba: 0.399162829832605

    - Conclusiones:
        Comparando los Modelos Finales de Random Forest y Elastic Net, el modelo Random Forest parece ser una mejor elecci√≥n en comparaci√≥n con el modelo Elastic Net. Esto se debe a que el modelo Random Forest presenta valores m√°s bajos de error cuadr√°tico medio (MSE) tanto en el conjunto de entrenamiento como en el conjunto de prueba, lo que indica una mejor capacidad de predicci√≥n y ajuste a los datos. Adem√°s, el coeficiente de determinaci√≥n (R^2) es m√°s alto en el modelo Random Forest, lo que indica que este modelo explica una mayor proporci√≥n de la varianza en los datos objetivo.

## Desafio Estructurando un Proyecto de DS (parte III)

- Requerimientos:

    - Crear√°n un notebook que complemente el trabajo realizado en los siguientes apartados: 
        - elegir un m√©todo de feature selection para reducir la dimensionalidad del dataset, 
        - elegir un algoritmo de regresi√≥n o clasificaci√≥n para entrenar con los datos elegidos,
        - c√°lculo de m√©tricas para validar el modelo
        - generar conclusiones con base en los resultados obtenidos.

- Archivo Implementaci√≥n Desafio:

https://github.com/IngLuissolis/CoderHouseDataScience/tree/main/Desafios/ProyectoDS_ParteIII_Solis.ipynb

- Consideraciones:

    - Se implemento dos selecci√≥n de caracteristicas ( Correlaci√≥n Pearson y Univariadas - Correlaci√≥n Lineal)
    - Se requiere una evaluaci√≥n adicional y considerar otros modelos para mejorar el rendimiento de los modelos planteados.

- Archivo Adicional Implementaci√≥n Desafio:

https://github.com/IngLuissolis/CoderHouseDataScience/tree/main/Desafios/ProyectoDS_ParteIII_Solis_bis.ipynb

    - Se implementaron dos modelos adicionales (Random Forest y Elastic Net). Los resultados obtenidos son los siguientes:

        - Random Forest:
            - Coeficiente de determinaci√≥n (R^2): 0.6992567213869347
            - Precisi√≥n en la predicci√≥n de los valores objetivos: 0.7936802973977695
            - Error absoluto medio (MAE): 0.40715663539269487 

            Conclusiones: Los resultados indican que el modelo de Random Forest tiene una capacidad moderada para explicar y predecir los valores objetivo, con un R^2 de 0.699 y una precisi√≥n del 79.4%. El MAE de 0.407 muestra una diferencia promedio entre los valores reales y las predicciones.

        - Elastic Net:
            - Coeficiente de determinaci√≥n (R^2): 0.14922875008453873
            - Precisi√≥n en la predicci√≥n de los valores objetivos: 0.14922875008453873
            - Error absoluto medio (MAE): 1.042423816912241

            Conclusiones: El modelo de Elastic Net con las variables seleccionadas explica solo el 14.92% de la variabilidad de la variable objetivo. La precisi√≥n en la predicci√≥n es baja y las predicciones tienen un error medio de 1.0424 unidades en la escala de la variable objetivo.


## Desafio Estructurando un Proyecto de DS (parte II)

- Requerimientos:

    - Abstracto con motivaci√≥n y audiencia
    - Preguntas/Hip√≥tesis que queremos resolver mediante el an√°lisis de datos
    - An√°lisis Exploratorio de Datos (EDA)
    - Con base en las visualizaciones y res√∫menes num√©ricos generados del desaf√≠o anterior dar recomendaciones basados en los insights observados.
    - Para esta oportunidad deber√°s tener avances en los apartados: Definici√≥n de objetivo, Contexto comercial, Problema Comercial, Contexto anal√≠tico, Exploraci√≥n de datos (EDA)

Archivo Implementaci√≥n Desafio:

https://github.com/IngLuissolis/CoderHouseDataScience/tree/main/Desafios/ProyectoDS_ParteII_Solis.ipynb

## Desafio Estructurando un Proyecto de DS (parte I)

- Requerimientos:

    - Generar preguntas de inter√©s o hip√≥tesis de inter√©s sobre el dataset elegido para el proyecto final.
    - Crear visualizaciones (univariados, bivariados o trivariados) junto con res√∫menes num√©ricos b√°sicos acordes con los tipos de variables disponibles.
    - Interpretar los resultados obtenidos

Archivo Implementaci√≥n Desafio:

https://github.com/IngLuissolis/CoderHouseDataScience/tree/main/Desafios/ProyectoDS_ParteI_Solis.ipynb

## Desafio Visualizaciones en Python

- Requerimientos:

    - Elegir uno de los datasets del desaf√≠o ‚ÄúElecci√≥n de Potenciales Datasets e importe con la librer√≠a Pandas‚Äù. Posteriormente crear√°n un notebook donde cargaran el archivo utilizando funciones de pandas para luego proceder a realizar 3 gr√°ficos diferentes con Matplotlib y 3 con Seaborn. Finalmente cada gr√°fico ser√° interpretado con el fin de obtener insights relevantes que permitan dar respuesta a la pregunta problema.

## Desafio Datasets con la librer√≠a Pandas

- Requerimientos:

    - Identificar 3 datasets que cumplan con las siguientes condiciones: a) al menos 2000 filas y b) al menos 15 columnas. Pueden buscar en las siguientes fuentes: GitLab, Github, Kaggle, Google Dataset Search (Si desean trabajar con un archivo propio se puede tambi√©n)
    - Cargar los archivos correspondientes por medio de la librer√≠a pandas
    - Describir las variables potencialmente interesantes en cada archivo teniendo en cuenta el contexto comercial y analitico involucrado

- Archivos formato .ipynb en carpeta:
    - https://github.com/IngLuissolis/CoderHouseDataScience/blob/main/Desafios/DesafioDatasetsSolis_01.ipynb

    - https://github.com/IngLuissolis/CoderHouseDataScience/blob/main/Desafios/DesafioDatasetsSolis_02.ipynb

    - https://github.com/IngLuissolis/CoderHouseDataScience/blob/main/Desafios/DesafioDatasetsSolis_03.ipynb


- Archivos .csv en carpeta:
https://github.com/IngLuissolis/CoderHouseDataScience/tree/main/DataSets

    - DataSet 01: 2022-2023FootballPlayerStats.csv
    - DataSet 02: FootballPlayersStatsPremier2022.csv
    - DataSet 03: 2022-2023Top5FootballLeaguesPlayerStats.csv


# Descripci√≥n del Proyecto:


# Estado del Proyecto

- Completar

# Tecnologias utilizadas

- Lenguaje programaci√≥n python

# Librerias utilizadas

- Completar

# Customer Homepage

Animaci√≥n Gif ecommerce

# Firebase - collection orders

Imagen CartContainer

# Sitio Deployed

url

# Feedback

Any suggestion and feedback is welcome. You can message me on email

`edusolis@yahoo.com.ar`
